{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mycloud\\AppData\\Local\\Temp\\ipykernel_7332\\3663892928.py:13: DtypeWarning: Columns (17,18,19,20,21,22,23,24,26,27,28,63,64) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, sep='^')\n",
      "C:\\Users\\Mycloud\\AppData\\Local\\Temp\\ipykernel_7332\\3663892928.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(df, ignore_index=True)\n",
      "C:\\Users\\Mycloud\\AppData\\Local\\Temp\\ipykernel_7332\\3663892928.py:13: DtypeWarning: Columns (18,20,21,22,23,24,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, sep='^')\n",
      "C:\\Users\\Mycloud\\AppData\\Local\\Temp\\ipykernel_7332\\3663892928.py:16: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all_data = all_data.append(df, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# combine csv in folders \n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def read_csv_files_in_folder(root_folder):\n",
    "    all_data = pd.DataFrame()\n",
    "\n",
    "    # Iterate over files in the root folder\n",
    "    for file_name in os.listdir(root_folder):\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(root_folder, file_name)\n",
    "            df = pd.read_csv(file_path, sep='^')\n",
    "            \n",
    "            # Append data to the combined DataFrame\n",
    "            all_data = all_data.append(df, ignore_index=True)\n",
    "    \n",
    "    return all_data\n",
    "\n",
    "root_folder = r'C:\\Users\\Mycloud\\Desktop\\suki'  # Specify the root folder containing CSV files\n",
    "\n",
    "combined_data = read_csv_files_in_folder(root_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['warehouse_no', 'bu', 'vender_id', 'shop_id', 'shop_name',\n",
       "       'parent_sale_ord_id', 'sale_ord_id', 'receiver_zipcode',\n",
       "       'ord_status_cd', 'cancel_flag', 'sale_ord_valid_flag', 'eclp_id',\n",
       "       'v_id', 'old_site_id', 'receive_site_code', 'receiving_time',\n",
       "       'positioning_time', 'packing_completion_time',\n",
       "       'sortcenter_reception_time', 'first_sorting_center_shipping_time',\n",
       "       'station_inspect_time', 'devlivery_site_name', 'delivery_time',\n",
       "       'reject_site_name', 'reject_time', 'pre_order_flag', 'scantype',\n",
       "       'processdate', 'ord_complete_tm', 'dept_id_1', 'dept_name_1',\n",
       "       'dept_id_2', 'dept_name_2', 'dept_id_3', 'dept_name_3', 'dept_id_4',\n",
       "       'dept_name_4', 'dept_id_5', 'dept_name_5', 'item_first_cate_cd',\n",
       "       'item_first_cate_name', 'item_second_cate_cd', 'item_second_cate_name',\n",
       "       'item_third_cate_cd', 'item_third_cate_name', 'brand_code',\n",
       "       'brand_name_full', 'presale_flag', 'item_sku_id', 'jd_prc', 'weight',\n",
       "       'length', 'width', 'gmv_amount', 'sale_qtty', 'pay_mode', 'sale_ord_tm',\n",
       "       'pay_tm', 'ord_cancel_tm', 'user_log_acct', 'source_cd',\n",
       "       'resource_name', 'bu.1', 'inbound_no', 'wh_receive_tm', 'height',\n",
       "       'share_buy_ord'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1006600014, 1006600003, 1006600007, 1006600010, 1006600001,\n",
       "       1006611111, 1006600004, 1006600015, 1006600017, 1006600018,\n",
       "       1006600006], dtype=int64)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check uniqe warehouse \n",
    "combined_data['warehouse_no'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete not relate wh with Logisteam \n",
    "filterwarehouse = combined_data.loc[combined_data['warehouse_no'].isin([1006600003, 1006600007,1006600001,\n",
    "       1006611111, 1006600004])]\n",
    "filterwarehouse['warehouse_no'].unique()\n",
    "#filter cancel orders \n",
    "filterwarehouse = filterwarehouse.loc[filterwarehouse['cancel_flag'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function create columns warehouse _name \n",
    "def warehouse_name(x):\n",
    "    if x == 1006600003:\n",
    "        return \"คลังบัวโรย C\" \n",
    "    elif x == 1006600007:\n",
    "        return \"คลังบางบ่อ\"\n",
    "    elif x == 1006600001:\n",
    "        return \"คลังสินค้านำเข้า\"\n",
    "    elif x == 1006611111:\n",
    "        return \"คลังสินค้า A6\"\n",
    "    elif x == 1006600004:\n",
    "        return \"คลังสินค้า Aftersale\"\n",
    "    \n",
    "filterwarehouse['Warehouse_name'] = filterwarehouse['warehouse_no'].apply(warehouse_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mycloud\\AppData\\Local\\Temp\\ipykernel_7332\\3472082609.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop_duplicates(subset='sale_ord_id',inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#filtercolumn\n",
    "\n",
    "df = filterwarehouse[['warehouse_no','Warehouse_name', 'sale_ord_id', 'receiver_zipcode',\n",
    "        'cancel_flag', 'sale_ord_valid_flag', 'eclp_id','receive_site_code', 'receiving_time','packing_completion_time','first_sorting_center_shipping_time',\n",
    "       'station_inspect_time','devlivery_site_name', 'delivery_time','pre_order_flag', 'scantype','dept_name_1',\n",
    "       'dept_name_2','dept_name_3', 'dept_name_4','dept_name_5','item_first_cate_name','item_second_cate_name',\n",
    "       'item_third_cate_name',\n",
    "       'brand_name_full', 'presale_flag', 'item_sku_id', 'jd_prc', 'weight',\n",
    "       'length', 'width','height', 'gmv_amount', 'sale_qtty', 'pay_mode', 'sale_ord_tm',\n",
    "       'pay_tm', 'ord_cancel_tm', 'user_log_acct', 'source_cd',\n",
    "       'resource_name', 'bu.1', 'inbound_no', 'wh_receive_tm', 'share_buy_ord',]]\n",
    "\n",
    "#dropduplicate by sale_ord_id \n",
    "df.drop_duplicates(subset='sale_ord_id',inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mycloud\\AppData\\Local\\Temp\\ipykernel_7332\\2766545495.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.sort_values(by='receiving_time',inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df.sort_values(by='receiving_time',inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>HUB</th>\n",
       "      <th>Party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>117</td>\n",
       "      <td>บางปลา</td>\n",
       "      <td>1PL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>149</td>\n",
       "      <td>B2B</td>\n",
       "      <td>B2B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>145</td>\n",
       "      <td>สมุทรปราการ</td>\n",
       "      <td>1PL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Code          HUB Party \n",
       "0   117      บางปลา     1PL\n",
       "1   149          B2B    B2B\n",
       "2   145  สมุทรปราการ    1PL"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#request json code of Logistic Party from git \n",
    "import requests\n",
    "def json_to_dataframe(url):\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        content = response.json()\n",
    "        df = pd.DataFrame(content)\n",
    "        return df\n",
    "    else:\n",
    "        print(\"Error: Failed to retrieve the content from the URL.\")\n",
    "        return None\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/sutiwatt/sutiwatt/main/code.json\"\n",
    "Party_logistic_code= json_to_dataframe(url)\n",
    "Party_logistic_code.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#merge data for group Logistic Party \n",
    "#due receive_site_code is flot astype to int \n",
    "Party_logistic_code['Code'] = Party_logistic_code['Code'].astype(float)\n",
    "df_1 = pd.merge(df,Party_logistic_code,how='left',left_on='receive_site_code',right_on='Code')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#request Api of latlong and province in thailand by function json_to_dataframe\n",
    "url = \"https://raw.githubusercontent.com/sutiwatt/Thai-zip-code-latitude-and-longitude/master/data.json\"\n",
    "province = json_to_dataframe(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "province['zip'] = province['zip'].astype(float)\n",
    "df_1['receiver_zipcode'] = df_1['receiver_zipcode'].astype(float)\n",
    "df_1 = pd.merge(df_1,province,how='left',left_on='receiver_zipcode',right_on='zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#found some zipcode duplicate with 2 or more distrinct SO remove duplicate again\n",
    "\n",
    "df_1.drop_duplicates(subset='sale_ord_id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['warehouse_no', 'Warehouse_name', 'sale_ord_id', 'receiver_zipcode',\n",
       "       'cancel_flag', 'sale_ord_valid_flag', 'eclp_id', 'receive_site_code',\n",
       "       'receiving_time', 'packing_completion_time',\n",
       "       'first_sorting_center_shipping_time', 'station_inspect_time',\n",
       "       'devlivery_site_name', 'delivery_time', 'pre_order_flag', 'scantype',\n",
       "       'dept_name_1', 'dept_name_2', 'dept_name_3', 'dept_name_4',\n",
       "       'dept_name_5', 'item_first_cate_name', 'item_second_cate_name',\n",
       "       'item_third_cate_name', 'brand_name_full', 'presale_flag',\n",
       "       'item_sku_id', 'jd_prc', 'weight', 'length', 'width', 'height',\n",
       "       'gmv_amount', 'sale_qtty', 'pay_mode', 'sale_ord_tm', 'pay_tm',\n",
       "       'ord_cancel_tm', 'user_log_acct', 'source_cd', 'resource_name', 'bu.1',\n",
       "       'inbound_no', 'wh_receive_tm', 'share_buy_ord', 'Code', 'HUB', 'Party ',\n",
       "       'id', 'zip', 'province', 'district', 'lat', 'lng'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert df time object to datetime \n",
    "\n",
    "# df_1['receiving_to_pack'] = df_1['packing_completion_time'] - df_1['receiving_time']\n",
    "# df_1['receiving_to_pack']\n",
    "\n",
    "columns_to_convert = ['receiving_time', 'packing_completion_time', 'first_sorting_center_shipping_time', 'delivery_time']\n",
    "\n",
    "for column in columns_to_convert:\n",
    "    df_1[column] = pd.to_datetime(df_1[column])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>receiving_to_pack</th>\n",
       "      <th>Pack_to_sort</th>\n",
       "      <th>sort_to_del</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.938056</td>\n",
       "      <td>2.568056</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.168889</td>\n",
       "      <td>0.917222</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.822222</td>\n",
       "      <td>5.222222</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.782500</td>\n",
       "      <td>4.862500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32.407778</td>\n",
       "      <td>16.986111</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471912</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471913</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471914</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471916</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1471918</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1024912 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         receiving_to_pack  Pack_to_sort  sort_to_del\n",
       "0                 3.938056      2.568056          0.0\n",
       "1                 1.168889      0.917222          0.0\n",
       "2                21.822222      5.222222          0.0\n",
       "3                21.782500      4.862500          0.0\n",
       "4                32.407778     16.986111          1.0\n",
       "...                    ...           ...          ...\n",
       "1471912                NaN           NaN          NaN\n",
       "1471913                NaN           NaN          NaN\n",
       "1471914                NaN           NaN          NaN\n",
       "1471916                NaN           NaN          NaN\n",
       "1471918                NaN           NaN          NaN\n",
       "\n",
       "[1024912 rows x 3 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1['receiving_to_pack'] = (df_1['packing_completion_time'] - df_1['receiving_time']).dt.total_seconds() / 3600\n",
    "df_1['Pack_to_sort'] = (df_1['first_sorting_center_shipping_time']-df_1['packing_completion_time']).dt.total_seconds() / 3600\n",
    "df_1['sort_to_del'] = (df_1['delivery_time'].dt.date - df_1['first_sorting_center_shipping_time'].dt.date).dt.days\n",
    "df_1[['receiving_to_pack','Pack_to_sort','sort_to_del']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function group time in warehouse \n",
    "def grouptime(x):\n",
    "    if x > 0 and x <= 1:\n",
    "        return \"under 1 hours\"\n",
    "    elif x > 1 and x <= 2 :\n",
    "        return \"1-2 hours\"\n",
    "    elif x > 2 and x <= 6 :\n",
    "        return \"2-6 hours\"\n",
    "    elif x > 6 and x <= 12:\n",
    "        return \"6-12 hours\"\n",
    "    elif x > 12 and x <= 24:\n",
    "        return \"12-24 hours\"\n",
    "    elif x > 24 :\n",
    "        return \"over 1 days\"\n",
    "    else:\n",
    "        return \"not Complete Process\"\n",
    "\n",
    "df_1['receiving_to_pack_group'] = df_1['receiving_to_pack'].apply(grouptime)\n",
    "df_1['Pack_to_sort_group'] = df_1['Pack_to_sort'].apply(grouptime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1['sort_to_del'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['In SLA', 'Over SLA', '0', 'still Shipping'], dtype=object)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use numpy help to match sla shipping under condition \n",
    "import numpy as np\n",
    "condition = [((df_1['Party '] == '1PL') & (df_1['sort_to_del'] <= 1)),\n",
    "             ((df_1['Party '] == '1PL') &  (df_1['sort_to_del'] > 1)),\n",
    "             ((df_1['Party '] == '3PL') &  (df_1['sort_to_del'] <= 2)),\n",
    "             ((df_1['Party '] == '3PL') &  (df_1['sort_to_del'] > 2)),\n",
    "             ((df_1['Party '] == 'B2B') &  (df_1['sort_to_del'] <= 3)),\n",
    "             ((df_1['Party '] == 'B2B') &  (df_1['sort_to_del'] > 3)),\n",
    "             (df_1['Party '].isnull())]\n",
    "result = ['In SLA','Over SLA','In SLA','Over SLA','In SLA','Over SLA','still Shipping']\n",
    "\n",
    "df_1['SLA_shipping'] =np.select(condition,result)\n",
    "df_1['SLA_shipping'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['Date'] = df_1['receiving_time'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columnes to push in google bigquery \n",
    "\n",
    "df_1.rename(columns={'bu.1':'bu'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['warehouse_no', 'Warehouse_name', 'sale_ord_id', 'receiver_zipcode',\n",
       "       'cancel_flag', 'sale_ord_valid_flag', 'eclp_id', 'receive_site_code',\n",
       "       'receiving_time', 'packing_completion_time',\n",
       "       'first_sorting_center_shipping_time', 'station_inspect_time',\n",
       "       'devlivery_site_name', 'delivery_time', 'pre_order_flag', 'scantype',\n",
       "       'dept_name_1', 'dept_name_2', 'dept_name_3', 'dept_name_4',\n",
       "       'dept_name_5', 'item_first_cate_name', 'item_second_cate_name',\n",
       "       'item_third_cate_name', 'brand_name_full', 'presale_flag',\n",
       "       'item_sku_id', 'jd_prc', 'weight', 'length', 'width', 'height',\n",
       "       'gmv_amount', 'sale_qtty', 'pay_mode', 'sale_ord_tm', 'pay_tm',\n",
       "       'ord_cancel_tm', 'user_log_acct', 'source_cd', 'resource_name', 'bu',\n",
       "       'inbound_no', 'wh_receive_tm', 'share_buy_ord', 'Code', 'HUB', 'Party ',\n",
       "       'id', 'zip', 'province', 'district', 'lat', 'lng', 'receiving_to_pack',\n",
       "       'Pack_to_sort', 'sort_to_del', 'receiving_to_pack_group',\n",
       "       'Pack_to_sort_group', 'SLA_shipping', 'Date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1[['receiving_time', 'packing_completion_time','first_sorting_center_shipping_time','delivery_time']] = df_1[['receiving_time', 'packing_completion_time','first_sorting_center_shipping_time','delivery_time']].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['sale_ord_id'] = df_1['sale_ord_id'].astype(str)\n",
    "df_1['warehouse_no'] = df_1['warehouse_no'].astype(str)\n",
    "df_1['receiver_zipcode'] = df_1['receiver_zipcode'].astype(str)\n",
    "df_1['sale_ord_id'] = df['sale_ord_id'].astype(str)\n",
    "df_1['Date'] = df_1['Date'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = df_1[['Warehouse_name','sale_ord_id','receiver_zipcode','packing_completion_time',\n",
    "       'first_sorting_center_shipping_time','delivery_time','pre_order_flag','dept_name_1', 'dept_name_2', 'dept_name_3', 'dept_name_4','dept_name_5', 'item_first_cate_name', 'item_second_cate_name',\n",
    "       'item_third_cate_name', 'brand_name_full', 'jd_prc','sale_qtty', 'pay_mode','HUB', 'Party ','zip', 'province', 'district', 'lat', 'lng','receiving_to_pack',\n",
    "       'Pack_to_sort', 'sort_to_del', 'receiving_to_pack_group',\n",
    "       'Pack_to_sort_group', 'SLA_shipping', 'Date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1048.58it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas_gbq\n",
    "project_id = 'sutwiatt001dashboard'\n",
    "destination_table = 'Flash_cost.Logistic_data_shipping'\n",
    "\n",
    "# Send DataFrame to BigQuery\n",
    "pandas_gbq.to_gbq(df_3, destination_table, project_id=project_id, if_exists='replace')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
